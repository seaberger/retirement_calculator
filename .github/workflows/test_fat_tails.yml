name: Fat-Tail Algorithm Tests

on:
  push:
    branches: [ main, develop, "fix/*", "feature/*" ]
    paths:
      - 'src/backend/monte_carlo/**'
      - 'tests/**'
      - '.github/workflows/test_fat_tails.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'src/backend/monte_carlo/**'
      - 'tests/**'
  schedule:
    # Run weekly to catch any drift
    - cron: '0 0 * * 0'

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install uv
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH
    
    - name: Install dependencies
      run: |
        uv venv
        source .venv/bin/activate
        uv pip install -r requirements.txt
        uv pip install pytest pytest-cov pytest-benchmark scipy
    
    - name: Run parameter bounds tests
      run: |
        source .venv/bin/activate
        pytest tests/test_parameter_bounds.py -v
    
    - name: Run toggle behavior tests
      run: |
        source .venv/bin/activate
        pytest tests/test_toggle_behavior.py -v
    
    - name: Run annual distribution tests
      run: |
        source .venv/bin/activate
        pytest tests/test_annual_distributions.py -v --tb=short
    
    - name: Run portfolio impact tests (CI guardrails)
      run: |
        source .venv/bin/activate
        pytest tests/test_fat_tail_impacts.py::TestImpactGuardrails -v
      continue-on-error: false  # Fail the build if guardrails are violated
    
    - name: Run full portfolio impact tests
      run: |
        source .venv/bin/activate
        pytest tests/test_fat_tail_impacts.py::TestPortfolioImpacts -v --tb=short
      continue-on-error: true  # Don't fail build, but report results
    
    - name: Generate coverage report
      run: |
        source .venv/bin/activate
        pytest tests/ --cov=src/backend/monte_carlo --cov-report=xml --cov-report=term
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: fat-tail-tests
        name: fat-tail-coverage
    
    - name: Performance benchmark
      run: |
        source .venv/bin/activate
        python -c "
import time
import sys
sys.path.insert(0, 'src/backend')
from monte_carlo.fat_tails_kou_logsafe import draw_fat_tailed_returns_kou_logsafe, FatTailCfg
import numpy as np

cfg = FatTailCfg(enabled=True)
mu = np.array([0.08, 0.04])
cov = np.array([[0.17**2, 0.01], [0.01, 0.08**2]])

start = time.time()
returns = draw_fat_tailed_returns_kou_logsafe(
    mu_arith=mu,
    cov_arith=cov,
    assets=['stocks', 'bonds'],
    n_years=35,
    n_sims=10000,
    cfg=cfg
)
elapsed = time.time() - start

print(f'Performance: {elapsed:.2f}s for 10,000 sims')
if elapsed > 1.0:
    print('WARNING: Performance degraded (>1.0s)')
    sys.exit(1)
"
    
    - name: Check parameter drift
      run: |
        source .venv/bin/activate
        python -c "
import json
import sys
sys.path.insert(0, 'src/backend')
from monte_carlo.fat_tails_kou_logsafe import FatTailCfg

cfg = FatTailCfg()

# Check critical parameters haven't drifted
assert cfg.t_df == 6.0, f't_df drifted to {cfg.t_df}'
assert cfg.market.lam == 0.25, f'market.lam drifted to {cfg.market.lam}'
assert cfg.market.eta_neg == 0.075, f'market.eta_neg drifted to {cfg.market.eta_neg}'
assert cfg.per_asset['stocks'].lam == 0.20, f'stock.lam drifted'

print('âœ… Parameters stable')
"

  notify:
    needs: test
    runs-on: ubuntu-latest
    if: failure()
    steps:
    - name: Notify on failure
      run: |
        echo "Fat-tail tests failed! Check parameter drift or impact changes."
        # Add Slack/email notification here if needed